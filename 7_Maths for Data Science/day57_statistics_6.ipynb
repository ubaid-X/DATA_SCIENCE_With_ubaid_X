{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0877b4f5",
   "metadata": {},
   "source": [
    "---\n",
    "__About Section:__\n",
    "\n",
    "- __Author name:__ UBAIDULLAH\n",
    "\n",
    "- __Email:__ [ai.bussiness.student0@gmail.com](mailto:ai.bussiness.student0@gmail.com)\n",
    "\n",
    "- __GitHub:__ [github.com/ubaid-X/](https://github.com/ubaid-X/)\n",
    "\n",
    "- __LinkedIn Profile:__ [linkedin.com/in/ubaid-ullah-634563373/](https://www.linkedin.com/in/ubaid-ullah-634563373/)\n",
    "\n",
    "- __Kaggle:__ [kaggle.com/ubaidullah01](https://www.kaggle.com/ubaidullah01)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d986ac2",
   "metadata": {},
   "source": [
    "# __Central Tendency:__\n",
    "\n",
    "Central tendency is a way to describe the center of a data set. It's like finding the heart of a city, the spot where everything comes alive. In data terms, it's the point around which the clusters. Think of it as a way to summarize a whole lot of numbers with just one vaue that represent them best.\n",
    "\n",
    "There are three main ways to measure central tendency:\n",
    "1. __Mean:__ The mean is what most people think of as the average. You add up all the numbers and then divide by how many numbers there are. It's like finding the balance point or the center of a dataset.\n",
    "\n",
    "   __Formula:__\n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n",
    "    Where:\n",
    "    - \\( \\bar{x} \\) = Mean\n",
    "    - \\( n \\) = Total number of observations\n",
    "    - \\( x_i \\) = Each individual observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae2c45",
   "metadata": {},
   "source": [
    "__Uses of Mean:__\n",
    "1. Simplicity: The mean is easy to calculate and understand, making it a popular choice for summarizing data.\n",
    "2. Comparison: It allows for easy comparison between different datasets or groups.\n",
    "3. Decision Making: In business and economics, the mean is often used to make informed decisions based on average performance or trends.\n",
    "4. Foundation for advance statistical analysis: Many statistical methods and tests are based on the mean, making it a fundamental concept in statistics.\n",
    "5. Data Analysis: The mean is widely used in various fields, including social sciences, healthcare, and education, to analyze and interpret data.\n",
    "\n",
    "# __Different types of Mean:__\n",
    "\n",
    "### 1. Arithmetic Mean\n",
    "\n",
    "**Definition:** The most common type of mean, it’s calculated by summing up all the values in a dataset and then dividing by the number of values.\n",
    "\n",
    "**Formula:**  \n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n",
    "\n",
    "\n",
    "**Usage:** Ideal for interval and ratio data, and when data is evenly distributed without extreme outliers.\n",
    "\n",
    "**Example:** Calculating the average income of a group of individuals.\n",
    "\n",
    "Consider the dataset: `5, 10, 15, 20, 25.`  \n",
    "\n",
    "$$ \\bar{x} = \\frac{5 + 10 + 15 + 20 + 25}{5} = \\frac{75}{5} = 15 $$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2aaf2c",
   "metadata": {},
   "source": [
    "### __2. Geometric Mean__\n",
    "\n",
    "## Definition\n",
    "The geometric mean is calculated by multiplying all the values together and then taking the nth root (where n is the number of values).\n",
    "\n",
    "## Formula\n",
    "\n",
    "$$ \\text{Geometric Mean} = \\left( \\prod_{i=1}^n x_i \\right)^{\\frac{1}{n}} $$\n",
    "\n",
    "## Usage\n",
    "Used for datasets that contain values with different ranges or units, such as growth rates. Commonly applied when calculating average growth rates in finance or biology.\n",
    "\n",
    "## Example\n",
    "Consider growth rates: \\([1.05, 1.08, 1.07]\\)\n",
    "\n",
    "\n",
    "$$ \\text{Geometric Mean} = (1.05 \\times 1.08 \\times 1.07)^{\\frac{1}{3}} \\approx 1.0667\n",
    "$$\n",
    "\n",
    "The average growth rate is approximately 1.0667 or 6.67%.\n",
    "\n",
    "## Verification\n",
    "Let's verify this calculation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c168d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: 1.2133800000000001\n",
      "Geometric Mean (method 1): 1.0666\n",
      "Geometric Mean (method 2): 1.0666\n",
      "Average growth rate: 6.66%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Given growth rates\n",
    "rates = [1.05, 1.08, 1.07]\n",
    "\n",
    "# Method 1: Using product and power\n",
    "product = 1.05 * 1.08 * 1.07\n",
    "geometric_mean = product ** (1/3)\n",
    "\n",
    "# Method 2: Using logarithms (more numerically stable)\n",
    "log_mean = math.exp((math.log(1.05) + math.log(1.08) + math.log(1.07)) / 3)\n",
    "\n",
    "print(f\"Product: {product}\")\n",
    "print(f\"Geometric Mean (method 1): {geometric_mean:.4f}\")\n",
    "print(f\"Geometric Mean (method 2): {log_mean:.4f}\")\n",
    "print(f\"Average growth rate: {(geometric_mean - 1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88146080",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __3. Harmonic Mean__\n",
    "\n",
    "## Definition\n",
    "The harmonic mean is the reciprocal of the arithmetic mean of the reciprocals of the values.\n",
    "\n",
    "## Formula\n",
    "\n",
    "$$ \\text{Harmonic Mean} = \\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}} $$\n",
    "\n",
    "\n",
    "## Usage\n",
    "Suitable for rates and ratios, like speeds or productivity measurements. Particularly useful when dealing with quantities that are defined in terms of some per unit amount.\n",
    "\n",
    "## Example\n",
    "Calculating the average speed of a round trip made at different speeds.\n",
    "\n",
    "Consider speeds (km/h): \\([40, 60, 80]\\)\n",
    "\n",
    "\n",
    "$$ \\text{Harmonic Mean} = \\frac{3}{\\frac{1}{40} + \\frac{1}{60} + \\frac{1}{80}} \\approx 53.33\n",
    "$$\n",
    "\n",
    "The harmonic mean speed is approximately 55.38 km/h.\n",
    "\n",
    "## Verification\n",
    "Let's verify this calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d79efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Harmonic Mean Verification ===\n",
      "Speeds: [40, 60, 80] km/h\n",
      "\n",
      "Step-by-step calculation:\n",
      "1/40 = 0.025000\n",
      "1/60 = 0.016667\n",
      "1/80 = 0.012500\n",
      "Sum of reciprocals = 0.054167\n",
      "Harmonic Mean = 3 / 0.054167 = 55.38\n",
      "\n",
      "Verification using different methods:\n",
      "Manual calculation: 55.38 km/h\n",
      "Scipy calculation: 55.38 km/h\n",
      "NumPy calculation: 55.38 km/h\n",
      "\n",
      "All methods confirm: Harmonic Mean = 55.38 km/h\n"
     ]
    }
   ],
   "source": [
    "# Correct verification code for harmonic mean\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Given speeds\n",
    "speeds = [40, 60, 80]\n",
    "\n",
    "# Method 1: Manual calculation\n",
    "reciprocal_sum = 1/40 + 1/60 + 1/80\n",
    "harmonic_mean_manual = 3 / reciprocal_sum\n",
    "\n",
    "# Method 2: Using scipy\n",
    "harmonic_mean_scipy = hmean(speeds)\n",
    "\n",
    "# Method 3: Using numpy\n",
    "harmonic_mean_numpy = len(speeds) / np.sum(1.0 / np.array(speeds))\n",
    "\n",
    "print(\"=== Harmonic Mean Verification ===\")\n",
    "print(f\"Speeds: {speeds} km/h\")\n",
    "print()\n",
    "print(\"Step-by-step calculation:\")\n",
    "print(f\"1/40 = {1/40:.6f}\")\n",
    "print(f\"1/60 = {1/60:.6f}\")\n",
    "print(f\"1/80 = {1/80:.6f}\")\n",
    "print(f\"Sum of reciprocals = {reciprocal_sum:.6f}\")\n",
    "print(f\"Harmonic Mean = 3 / {reciprocal_sum:.6f} = {harmonic_mean_manual:.2f}\")\n",
    "print()\n",
    "print(\"Verification using different methods:\")\n",
    "print(f\"Manual calculation: {harmonic_mean_manual:.2f} km/h\")\n",
    "print(f\"Scipy calculation: {harmonic_mean_scipy:.2f} km/h\")\n",
    "print(f\"NumPy calculation: {harmonic_mean_numpy:.2f} km/h\")\n",
    "print()\n",
    "print(\"All methods confirm: Harmonic Mean = 55.38 km/h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9fff05",
   "metadata": {},
   "source": [
    "**Why harmonic mean for speeds:** If you travel equal distances at different speeds, the harmonic mean gives the true average speed for the entire journey.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39246",
   "metadata": {},
   "source": [
    "# 5. Truncated (or Trimmed) Mean\n",
    "\n",
    "### __Definition__\n",
    "The truncated mean involves removing a certain percentage of the smallest and largest values before calculating the mean.\n",
    "\n",
    "## Usage\n",
    "Helpful in reducing the impact of outliers or extreme values. Commonly used when analyzing data such as income or property values, where extreme values can skew the results.\n",
    "\n",
    "## Formula\n",
    "For a dataset of size $ n $ with trimming proportion $ \\alpha $ :\n",
    "\n",
    "\n",
    "$$ \\text{Trimmed Mean} = \\frac{1}{n(1-2\\alpha)} \\sum_{i=k+1}^{n-k} x_{(i)}\n",
    "$$\n",
    "where $ k = \\lfloor \\alpha \\cdot n \\rfloor $ and  $ x_{(i)} $ represents the ordered data.\n",
    "\n",
    "## Example\n",
    "Consider the dataset: \\([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\) with 10% trimming from each end.\n",
    "\n",
    "**Step-by-step calculation:**\n",
    "- Original dataset: \\([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\) (n = 10)\n",
    "- 10% of 10 = 1 value to remove from each end\n",
    "- Remove bottom 10%: remove 1\n",
    "- Remove top 10%: remove 10\n",
    "- Trimmed dataset: \\([2, 3, 4, 5, 6, 7, 8, 9]\\)\n",
    "- Trimmed Mean = \\(\\frac{2+3+4+5+6+7+8+9}{8} = \\frac{44}{8} = 5.5\\)\n",
    "\n",
    "## Verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe71abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Truncated Mean Verification ===\n",
      "Original dataset: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Dataset size: 10\n",
      "Values to trim from each end: 1\n",
      "Trimmed dataset: [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "Step-by-step calculation:\n",
      "Sum of trimmed values: 44\n",
      "Count of trimmed values: 8\n",
      "Trimmed Mean = 44 / 8 = 5.5\n",
      "\n",
      "Verification using different methods:\n",
      "Manual calculation: 5.5\n",
      "Scipy calculation: 5.5\n",
      "NumPy calculation: 5.5\n",
      "\n",
      "All methods confirm: Trimmed Mean = 5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "# Given dataset\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Method 1: Manual calculation\n",
    "print(\"=== Truncated Mean Verification ===\")\n",
    "print(f\"Original dataset: {data}\")\n",
    "print(f\"Dataset size: {len(data)}\")\n",
    "\n",
    "# Calculate number of values to trim (10% from each end)\n",
    "trim_fraction = 0.10\n",
    "n_trim = int(len(data) * trim_fraction)\n",
    "print(f\"Values to trim from each end: {n_trim}\")\n",
    "\n",
    "# Sort the data and trim\n",
    "sorted_data = sorted(data)\n",
    "trimmed_data = sorted_data[n_trim:len(data)-n_trim]\n",
    "print(f\"Trimmed dataset: {trimmed_data}\")\n",
    "\n",
    "# Calculate trimmed mean manually\n",
    "trimmed_mean_manual = sum(trimmed_data) / len(trimmed_data)\n",
    "\n",
    "# Method 2: Using scipy\n",
    "trimmed_mean_scipy = trim_mean(data, trim_fraction)\n",
    "\n",
    "# Method 3: Using numpy\n",
    "trimmed_mean_numpy = np.mean(trimmed_data)\n",
    "\n",
    "print(\"\\nStep-by-step calculation:\")\n",
    "print(f\"Sum of trimmed values: {sum(trimmed_data)}\")\n",
    "print(f\"Count of trimmed values: {len(trimmed_data)}\")\n",
    "print(f\"Trimmed Mean = {sum(trimmed_data)} / {len(trimmed_data)} = {trimmed_mean_manual}\")\n",
    "\n",
    "print(\"\\nVerification using different methods:\")\n",
    "print(f\"Manual calculation: {trimmed_mean_manual}\")\n",
    "print(f\"Scipy calculation: {trimmed_mean_scipy}\")\n",
    "print(f\"NumPy calculation: {trimmed_mean_numpy}\")\n",
    "\n",
    "print(f\"\\nAll methods confirm: Trimmed Mean = {trimmed_mean_manual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484bf21",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparison with Regular Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d5c086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison ===\n",
      "Regular Mean: 5.5\n",
      "Trimmed Mean: 5.5\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compare with regular mean\n",
    "regular_mean = np.mean(data)\n",
    "print(f\"\\n=== Comparison ===\")\n",
    "print(f\"Regular Mean: {regular_mean}\")\n",
    "print(f\"Trimmed Mean: {trimmed_mean_manual}\")\n",
    "print(f\"Difference: {regular_mean - trimmed_mean_manual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba483a",
   "metadata": {},
   "source": [
    "**Note:** In this symmetric dataset, both the regular mean and trimmed mean yield the same result (5.5). However, in datasets with outliers or skewed distributions, the trimmed mean would provide a more robust central tendency measure that is less influenced by extreme values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420293e",
   "metadata": {},
   "source": [
    "# How to culculate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "954ae495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0667a9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ccb78",
   "metadata": {},
   "source": [
    "---\n",
    "- Basic means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb1a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(32.204207968574636)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71e486",
   "metadata": {},
   "source": [
    "---\n",
    "- Geometric Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ea3c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(45.28728688116765)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "data = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "\n",
    "stats.gmean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6215643",
   "metadata": {},
   "source": [
    "---\n",
    "- Hormonic Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958cb2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(34.14171521474054)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.hmean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d4ce9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Truncated Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0f343a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Computer Valley\\.conda\\envs\\DS_Env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3859: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Computer Valley\\.conda\\envs\\DS_Env\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.trim_mean(data, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de123b4",
   "metadata": {},
   "source": [
    "the Other Argument in `stats.trim_mean()` is the proportion to cut off from each end of the data before calculating the mean. For example, if you set it to 0.1, it will remove the lowest 10% and the highest 10% of the data points before computing the mean of the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8569d7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(55.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86935451",
   "metadata": {},
   "source": [
    "# Limitations of Means\n",
    "\n",
    "### Overview\n",
    "While means are widely used measures of central tendency, each type has specific limitations and scenarios where they may not be appropriate. Understanding these limitations is crucial for proper statistical analysis.\n",
    "\n",
    "### 1. Arithmetic Mean Limitations\n",
    "- #### __Sensitivity to Outliers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6edbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Arithmetic Mean - Outlier Sensitivity ===\n",
      "Normal data: [45, 50, 55, 60, 65]\n",
      "Mean: 55.0\n",
      "Data with outlier: [45, 50, 55, 60, 200]\n",
      "Mean: 82.0\n",
      "Impact of outlier: 27.0 units\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example demonstrating outlier sensitivity\n",
    "data_normal = [45, 50, 55, 60, 65]\n",
    "data_with_outlier = [45, 50, 55, 60, 200]  # One extreme value\n",
    "\n",
    "mean_normal = np.mean(data_normal)\n",
    "mean_with_outlier = np.mean(data_with_outlier)\n",
    "\n",
    "print(\"=== Arithmetic Mean - Outlier Sensitivity ===\")\n",
    "print(f\"Normal data: {data_normal}\")\n",
    "print(f\"Mean: {mean_normal}\")\n",
    "print(f\"Data with outlier: {data_with_outlier}\")\n",
    "print(f\"Mean: {mean_with_outlier}\")\n",
    "print(f\"Impact of outlier: {mean_with_outlier - mean_normal:.1f} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723299b1",
   "metadata": {},
   "source": [
    "---\n",
    "-  ###  __Not Suitable for Skewed Distributions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20701a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Skewed Distribution Example ===\n",
      "Salaries: [30000, 32000, 35000, 38000, 40000, 42000, 45000, 50000, 60000, 200000]\n",
      "Arithmetic Mean: $57,200.00\n",
      "Median: $41,000.00\n",
      "Difference: $16,200.00\n"
     ]
    }
   ],
   "source": [
    "# Skewed distribution example\n",
    "salaries = [30000, 32000, 35000, 38000, 40000, 42000, 45000, 50000, 60000, 200000]\n",
    "mean_salary = np.mean(salaries)\n",
    "median_salary = np.median(salaries)\n",
    "\n",
    "print(\"\\n=== Skewed Distribution Example ===\")\n",
    "print(f\"Salaries: {salaries}\")\n",
    "print(f\"Arithmetic Mean: ${mean_salary:,.2f}\")\n",
    "print(f\"Median: ${median_salary:,.2f}\")\n",
    "print(f\"Difference: ${mean_salary - median_salary:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823425d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Geometric Mean Limitations\n",
    "- #### __Cannot Handle Zero or Negative Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3298180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Geometric Mean Limitations ===\n",
      "Case 1: [1, 2, 3, 4, 5] -> 2.6051710846973517\n",
      "Case 2: [1, 2, 0, 4, 5] -> Cannot compute - data contains zero or negative values\n",
      "Case 3: [1, 2, -3, 4, 5] -> Cannot compute - data contains zero or negative values\n",
      "Case 4: [1.05, 1.08, 1.07] -> 1.0665935279712864\n"
     ]
    }
   ],
   "source": [
    "def geometric_mean_safe(data):\n",
    "    \"\"\"Calculate geometric mean with error handling\"\"\"\n",
    "    try:\n",
    "        if any(x <= 0 for x in data):\n",
    "            return \"Cannot compute - data contains zero or negative values\"\n",
    "        return np.exp(np.mean(np.log(data)))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    [1, 2, 3, 4, 5],           # Normal case\n",
    "    [1, 2, 0, 4, 5],           # Contains zero\n",
    "    [1, 2, -3, 4, 5],          # Contains negative\n",
    "    [1.05, 1.08, 1.07]         # Growth rates\n",
    "]\n",
    "\n",
    "print(\"=== Geometric Mean Limitations ===\")\n",
    "for i, data in enumerate(test_cases, 1):\n",
    "    result = geometric_mean_safe(data)\n",
    "    print(f\"Case {i}: {data} -> {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200eee0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Harmonic Mean Limitations\n",
    "- #### __Extreme Sensitivity to Small Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57bc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Harmonic Mean Sensitivity ===\n",
      "Normal speeds: [40, 50, 60]\n",
      "Harmonic mean: 48.65\n",
      "Arithmetic mean: 50.00\n",
      "\n",
      "Speeds with small value: [5, 50, 60]\n",
      "Harmonic mean: 12.68\n",
      "Arithmetic mean: 38.33\n",
      "\n",
      "Harmonic mean change: -73.9%\n",
      "Arithmetic mean change: -23.3%\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def demonstrate_harmonic_sensitivity():\n",
    "    speeds_normal = [40, 50, 60]\n",
    "    speeds_with_small = [5, 50, 60]  # One very small value\n",
    "    \n",
    "    harmonic_normal = hmean(speeds_normal)\n",
    "    harmonic_with_small = hmean(speeds_with_small)\n",
    "    arithmetic_normal = np.mean(speeds_normal)\n",
    "    arithmetic_with_small = np.mean(speeds_with_small)\n",
    "    \n",
    "    print(\"=== Harmonic Mean Sensitivity ===\")\n",
    "    print(f\"Normal speeds: {speeds_normal}\")\n",
    "    print(f\"Harmonic mean: {harmonic_normal:.2f}\")\n",
    "    print(f\"Arithmetic mean: {arithmetic_normal:.2f}\")\n",
    "    \n",
    "    print(f\"\\nSpeeds with small value: {speeds_with_small}\")\n",
    "    print(f\"Harmonic mean: {harmonic_with_small:.2f}\")\n",
    "    print(f\"Arithmetic mean: {arithmetic_with_small:.2f}\")\n",
    "    \n",
    "    print(f\"\\nHarmonic mean change: {((harmonic_with_small - harmonic_normal) / harmonic_normal) * 100:.1f}%\")\n",
    "    print(f\"Arithmetic mean change: {((arithmetic_with_small - arithmetic_normal) / arithmetic_normal) * 100:.1f}%\")\n",
    "\n",
    "demonstrate_harmonic_sensitivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab8061",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Truncated Mean Limitations\n",
    "- #### __Arbitrary Trimming Percentage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004ea1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Truncated Mean - Percentage Sensitivity ===\n",
      "Original data: [10, 12, 13, 14, 15, 16, 17, 18, 19, 100]\n",
      "Arithmetic mean: 23.40\n",
      "Median: 15.50\n",
      "\n",
      "0% trimming: 23.40 (keeps 10 values)\n",
      "10% trimming: 15.50 (keeps 8 values)\n",
      "20% trimming: 15.50 (keeps 6 values)\n",
      "30% trimming: 15.50 (keeps 4 values)\n",
      "40% trimming: 15.50 (keeps 2 values)\n"
     ]
    }
   ],
   "source": [
    "def analyze_trimming_effect(data, trim_percentages):\n",
    "    \"\"\"Show how different trimming percentages affect the result\"\"\"\n",
    "    print(\"=== Truncated Mean - Percentage Sensitivity ===\")\n",
    "    print(f\"Original data: {data}\")\n",
    "    print(f\"Arithmetic mean: {np.mean(data):.2f}\")\n",
    "    print(f\"Median: {np.median(data):.2f}\")\n",
    "    print()\n",
    "    \n",
    "    for trim_pct in trim_percentages:\n",
    "        if trim_pct >= 0.5:\n",
    "            continue  # Skip cases that would trim all data\n",
    "        trimmed = trim_mean(data, trim_pct)\n",
    "        n_trim = int(len(data) * trim_pct)\n",
    "        values_kept = len(data) - 2 * n_trim\n",
    "        print(f\"{trim_pct*100:.0f}% trimming: {trimmed:.2f} (keeps {values_kept} values)\")\n",
    "\n",
    "# Test with skewed data\n",
    "skewed_data = [10, 12, 13, 14, 15, 16, 17, 18, 19, 100]\n",
    "trim_percentages = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "analyze_trimming_effect(skewed_data, trim_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13986336",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. General Limitations Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "008210cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY OF LIMITATIONS ===\n",
      "\n",
      "Arithmetic Mean:\n",
      "  • Highly sensitive to outliers\n",
      "  • Not robust for skewed distributions\n",
      "  • Can be misleading with extreme values\n",
      "\n",
      "Geometric Mean:\n",
      "  • Cannot handle zero or negative values\n",
      "  • Less intuitive interpretation\n",
      "  • Requires all positive values\n",
      "\n",
      "Harmonic Mean:\n",
      "  • Extremely sensitive to small values\n",
      "  • Heavily weighted by low values\n",
      "  • Not suitable for datasets with zeros\n",
      "\n",
      "Truncated Mean:\n",
      "  • Arbitrary choice of trimming percentage\n",
      "  • Loss of information from removed data\n",
      "  • Different percentages yield different results\n"
     ]
    }
   ],
   "source": [
    "# Check the Output First\n",
    "def summarize_limitations():\n",
    "    limitations = {\n",
    "        \"Arithmetic Mean\": [\n",
    "            \"Highly sensitive to outliers\",\n",
    "            \"Not robust for skewed distributions\",\n",
    "            \"Can be misleading with extreme values\"\n",
    "        ],\n",
    "        \"Geometric Mean\": [\n",
    "            \"Cannot handle zero or negative values\",\n",
    "            \"Less intuitive interpretation\",\n",
    "            \"Requires all positive values\"\n",
    "        ],\n",
    "        \"Harmonic Mean\": [\n",
    "            \"Extremely sensitive to small values\",\n",
    "            \"Heavily weighted by low values\",\n",
    "            \"Not suitable for datasets with zeros\"\n",
    "        ],\n",
    "        \"Truncated Mean\": [\n",
    "            \"Arbitrary choice of trimming percentage\",\n",
    "            \"Loss of information from removed data\",\n",
    "            \"Different percentages yield different results\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"=== SUMMARY OF LIMITATIONS ===\")\n",
    "    for mean_type, limits in limitations.items():\n",
    "        print(f\"\\n{mean_type}:\")\n",
    "        for limit in limits:\n",
    "            print(f\"  • {limit}\")\n",
    "\n",
    "summarize_limitations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c4ab9",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Practical Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a163c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUIDELINES FOR CHOOSING APPROPRIATE MEAN ===\n",
      "Large range in data (potential outliers):\n",
      "  → Use Median or Truncated Mean\n",
      "  → Be cautious with Arithmetic Mean\n",
      "Outliers detected: [100]\n",
      "  → Use Median or Truncated Mean\n",
      "  → Arithmetic Mean may be misleading\n"
     ]
    }
   ],
   "source": [
    "# Check the Output First\n",
    "def choose_appropriate_mean(data, data_type=\"values\"):\n",
    "    \"\"\"Guide to choosing the right mean based on data characteristics\"\"\"\n",
    "    \n",
    "    print(\"=== GUIDELINES FOR CHOOSING APPROPRIATE MEAN ===\")\n",
    "    \n",
    "    if any(x <= 0 for x in data):\n",
    "        print(\"Data contains zero or negative values:\")\n",
    "        print(\"  → Use Arithmetic Mean or Median\")\n",
    "        print(\"  → Avoid Geometric and Harmonic means\")\n",
    "        return\n",
    "    \n",
    "    if data_type == \"rates\" or data_type == \"ratios\":\n",
    "        print(\"For rates or ratios:\")\n",
    "        print(\"  → Consider Harmonic Mean for averaging rates\")\n",
    "        print(\"  → Consider Geometric Mean for growth rates\")\n",
    "    \n",
    "    if data_type == \"values\" and (max(data) / min(data) > 10):\n",
    "        print(\"Large range in data (potential outliers):\")\n",
    "        print(\"  → Use Median or Truncated Mean\")\n",
    "        print(\"  → Be cautious with Arithmetic Mean\")\n",
    "    \n",
    "    # Check for outliers using IQR method\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = [x for x in data if x < (Q1 - 1.5*IQR) or x > (Q3 + 1.5*IQR)]\n",
    "    \n",
    "    if outliers:\n",
    "        print(f\"Outliers detected: {outliers}\")\n",
    "        print(\"  → Use Median or Truncated Mean\")\n",
    "        print(\"  → Arithmetic Mean may be misleading\")\n",
    "\n",
    "# Example usage\n",
    "test_data = [1, 2, 3, 4, 5, 100]  # Contains outlier\n",
    "choose_appropriate_mean(test_data, \"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa7d42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __Key Takeaways:__\n",
    "1. Always consider the data distribution before choosing a measure of central tendency\n",
    "\n",
    "2. Arithmetic mean is most affected by outliers and extreme values\n",
    "\n",
    "3. Geometric mean requires strictly positive values\n",
    "\n",
    "4. Harmonic mean is heavily influenced by small values\n",
    "\n",
    "5. No single mean is universally best - choose based on context and data characteristics\n",
    "\n",
    "6. Consider using median for skewed distributions or when outliers are present\n",
    "\n",
    "7. Always visualize your data to understand its distribution before calculating means\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ce466",
   "metadata": {},
   "source": [
    "# __2. Median__\n",
    "\n",
    "## 1. Definition\n",
    "The **median** is a measure of central tendency that represents the middle value in a sorted dataset. It divides the data into two equal halves, where 50% of the values lie below and 50% lie above the median. Unlike the mean, the median is robust to outliers and skewed distributions.\n",
    "\n",
    "## 2. Formula and Calculation\n",
    "### For an Odd Number of Observations:\n",
    "\n",
    "$$ \\text{Median} = \\left(\\frac{n + 1}{2}\\right) \\text{Value} $$\n",
    "\n",
    "### For an Even Number of Observations:\n",
    "$$\n",
    "\\text{Median} = \\frac{\\left(\\frac{n}{2}\\right) \\text{Value} + \\left(\\frac{n}{2} + 1\\right) \\text{Value}}{2}\n",
    "$$\n",
    "\n",
    "**Steps to Calculate:**\n",
    "1. Sort the dataset in ascending order.\n",
    "2. Determine if the number of observations \\(n\\) is odd or even.\n",
    "3. Apply the formula accordingly.\n",
    "\n",
    "## 3. Example Calculation\n",
    "Let’s calculate the median for two datasets using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f5ad95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (Odd): [12, 8, 3, 15, 7]\n",
      "Sorted Data: [3, 7, 8, 12, 15]\n",
      "Median (Odd): 8.0\n",
      "Manual Check (Odd): 8\n"
     ]
    }
   ],
   "source": [
    "# Import required library\n",
    "import numpy as np\n",
    "\n",
    "# Example 1: Odd number of observations\n",
    "data_odd = [12, 8, 3, 15, 7]\n",
    "sorted_odd = sorted(data_odd)\n",
    "n_odd = len(sorted_odd)\n",
    "median_odd = np.median(data_odd)\n",
    "\n",
    "print(\"Dataset (Odd):\", data_odd)\n",
    "print(\"Sorted Data:\", sorted_odd)\n",
    "print(\"Median (Odd):\", median_odd)\n",
    "print(\"Manual Check (Odd):\", sorted_odd[n_odd // 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb611213",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c0145a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset (Even): [20, 14, 8, 5, 3, 2]\n",
      "Sorted Data: [2, 3, 5, 8, 14, 20]\n",
      "Median (Even): 6.5\n",
      "Manual Check (Even): 6.5\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Even number of observations\n",
    "data_even = [20, 14, 8, 5, 3, 2]\n",
    "sorted_even = sorted(data_even)\n",
    "n_even = len(sorted_even)\n",
    "median_even = np.median(data_even)\n",
    "\n",
    "print(\"\\nDataset (Even):\", data_even)\n",
    "print(\"Sorted Data:\", sorted_even)\n",
    "print(\"Median (Even):\", median_even)\n",
    "print(\"Manual Check (Even):\", (sorted_even[n_even // 2 - 1] + sorted_even[n_even // 2]) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffdeba",
   "metadata": {},
   "source": [
    "## 4. Uses of Median\n",
    "1. **Skewed Distributions:** Preferred over the mean for skewed data (e.g., income, property prices).\n",
    "2. **Outlier Resistance:** Unaffected by extreme values.\n",
    "3. **Ordinal Data:** Suitable for non-numeric data where values can be ranked.\n",
    "4. **Survival Analysis:** Used in fields like epidemiology for \"median survival time.\"\n",
    "\n",
    "## 5. Limitations of Median\n",
    "1. **Ignores Magnitude:** Does not consider all values in the dataset (e.g., [1, 2, 3] and [1, 2, 100] both have a median of 2).\n",
    "2. **Less Efficient for Inference:** Harder to use in statistical models compared to the mean.\n",
    "3. **Data Must Be Ordered:** Requires sortable data (not suitable for nominal categories like \"colors\").\n",
    "4. **Sampling Variability:** More sensitive to sampling variability than the mean for symmetric distributions.\n",
    "\n",
    "## 6. Summary\n",
    "The median is a robust measure of central tendency ideal for skewed data or when outliers are present. However, it should be avoided when precise mathematical operations or full data utilization is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29027530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(28.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74163821",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# __3. Mode__\n",
    "\n",
    "## 1. Definition\n",
    "The **mode** is a measure of central tendency that represents the most frequently occurring value in a dataset. Unlike the mean and median, the mode can be used with both numerical and categorical data. A dataset can have:\n",
    "- **One mode** (unimodal)\n",
    "- **Two modes** (bimodal) \n",
    "- **Multiple modes** (multimodal)\n",
    "- **No mode** (all values occur with equal frequency)\n",
    "\n",
    "## 2. Formula and Calculation\n",
    "There is no algebraic formula for the mode. It is determined by:\n",
    "\n",
    "### Calculation Steps:\n",
    "1. **Sort** the dataset in ascending order\n",
    "2. **Count** the number of observations (n)\n",
    "3. **Determine** if n is odd or even\n",
    "4. **Apply** the appropriate formula\n",
    "5. **Calculate** the median value\n",
    "\n",
    "\n",
    "## 3. Example Calculation\n",
    "Let's calculate the mode for different datasets using Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cfd588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEDIAN CALCULATION EXAMPLES ===\n",
      "\n",
      "Example 1: Odd Number of Observations\n",
      "Original data: [45, 23, 78, 12, 89, 5, 67]\n",
      "Sorted data: [5, 12, 23, 45, 67, 78, 89]\n",
      "Number of observations (n): 7\n",
      "Median position: 4\n",
      "Median value (manual): 45\n",
      "Median value (numpy): 45.0\n",
      "Median value (statistics): 45\n",
      "Verification: All methods agree? True\n",
      "\n",
      "Example 2: Even Number of Observations\n",
      "Original data: [34, 12, 89, 23, 45, 67, 8, 91]\n",
      "Sorted data: [8, 12, 23, 34, 45, 67, 89, 91]\n",
      "Number of observations (n): 8\n",
      "Median positions: 4 and 5\n",
      "Values at positions: 34 and 45\n",
      "Median value (manual): 39.5\n",
      "Median value (numpy): 39.5\n",
      "Median value (statistics): 39.5\n",
      "Verification: All methods agree? True\n",
      "\n",
      "Example 3: Real-world Scenario - House Prices\n",
      "House prices: [250000, 275000, 300000, 320000, 350000, 280000, 265000, 1000000]\n",
      "Sorted prices: [250000, 265000, 275000, 280000, 300000, 320000, 350000, 1000000]\n",
      "Median house price: $290,000.00\n",
      "Mean house price: $380,000.00\n",
      "Difference: $90,000.00\n",
      "Note: The median is less affected by the $1,000,000 outlier\n",
      "\n",
      "Example 4: Robustness to Outliers\n",
      "Normal dataset:\n",
      "Data: [10, 12, 13, 14, 15]\n",
      "Mean: 12.80, Median: 13.0\n",
      "\n",
      "Dataset with outlier:\n",
      "Data: [10, 12, 13, 14, 100]\n",
      "Mean: 29.80, Median: 13.0\n",
      "Mean change: 17.00\n",
      "Median change: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "print(\"=== MEDIAN CALCULATION EXAMPLES ===\\n\")\n",
    "\n",
    "# Example 1: Odd number of observations\n",
    "print(\"Example 1: Odd Number of Observations\")\n",
    "data_odd = [45, 23, 78, 12, 89, 5, 67]\n",
    "sorted_odd = sorted(data_odd)\n",
    "n_odd = len(data_odd)\n",
    "median_position_odd = (n_odd + 1) // 2\n",
    "median_odd_numpy = np.median(data_odd)\n",
    "median_odd_stats = statistics.median(data_odd)\n",
    "median_odd_manual = sorted_odd[median_position_odd - 1]  # -1 for zero-based indexing\n",
    "\n",
    "print(f\"Original data: {data_odd}\")\n",
    "print(f\"Sorted data: {sorted_odd}\")\n",
    "print(f\"Number of observations (n): {n_odd}\")\n",
    "print(f\"Median position: {median_position_odd}\")\n",
    "print(f\"Median value (manual): {median_odd_manual}\")\n",
    "print(f\"Median value (numpy): {median_odd_numpy}\")\n",
    "print(f\"Median value (statistics): {median_odd_stats}\")\n",
    "print(f\"Verification: All methods agree? {median_odd_manual == median_odd_numpy == median_odd_stats}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Even number of observations\n",
    "print(\"Example 2: Even Number of Observations\")\n",
    "data_even = [34, 12, 89, 23, 45, 67, 8, 91]\n",
    "sorted_even = sorted(data_even)\n",
    "n_even = len(data_even)\n",
    "median_position1 = n_even // 2\n",
    "median_position2 = (n_even // 2) + 1\n",
    "median_even_numpy = np.median(data_even)\n",
    "median_even_stats = statistics.median(data_even)\n",
    "median_even_manual = (sorted_even[median_position1 - 1] + sorted_even[median_position2 - 1]) / 2\n",
    "\n",
    "print(f\"Original data: {data_even}\")\n",
    "print(f\"Sorted data: {sorted_even}\")\n",
    "print(f\"Number of observations (n): {n_even}\")\n",
    "print(f\"Median positions: {median_position1} and {median_position2}\")\n",
    "print(f\"Values at positions: {sorted_even[median_position1 - 1]} and {sorted_even[median_position2 - 1]}\")\n",
    "print(f\"Median value (manual): {median_even_manual}\")\n",
    "print(f\"Median value (numpy): {median_even_numpy}\")\n",
    "print(f\"Median value (statistics): {median_even_stats}\")\n",
    "print(f\"Verification: All methods agree? {abs(median_even_manual - median_even_numpy) < 0.001}\")\n",
    "print()\n",
    "\n",
    "# Example 3: Real-world scenario - House prices (with outlier)\n",
    "print(\"Example 3: Real-world Scenario - House Prices\")\n",
    "house_prices = [250000, 275000, 300000, 320000, 350000, 280000, 265000, 1000000]  # Last price is an outlier\n",
    "sorted_prices = sorted(house_prices)\n",
    "median_price = np.median(house_prices)\n",
    "mean_price = np.mean(house_prices)\n",
    "\n",
    "print(f\"House prices: {house_prices}\")\n",
    "print(f\"Sorted prices: {sorted_prices}\")\n",
    "print(f\"Median house price: ${median_price:,.2f}\")\n",
    "print(f\"Mean house price: ${mean_price:,.2f}\")\n",
    "print(f\"Difference: ${mean_price - median_price:,.2f}\")\n",
    "print(\"Note: The median is less affected by the $1,000,000 outlier\")\n",
    "print()\n",
    "\n",
    "# Example 4: Comparison with outliers\n",
    "print(\"Example 4: Robustness to Outliers\")\n",
    "normal_data = [10, 12, 13, 14, 15]\n",
    "outlier_data = [10, 12, 13, 14, 100]  # Last value is an outlier\n",
    "\n",
    "print(\"Normal dataset:\")\n",
    "print(f\"Data: {normal_data}\")\n",
    "print(f\"Mean: {np.mean(normal_data):.2f}, Median: {np.median(normal_data)}\")\n",
    "\n",
    "print(\"\\nDataset with outlier:\")\n",
    "print(f\"Data: {outlier_data}\")\n",
    "print(f\"Mean: {np.mean(outlier_data):.2f}, Median: {np.median(outlier_data)}\")\n",
    "print(f\"Mean change: {np.mean(outlier_data) - np.mean(normal_data):.2f}\")\n",
    "print(f\"Median change: {np.median(outlier_data) - np.median(normal_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170a3cf",
   "metadata": {},
   "source": [
    "## 4. Uses of Median\n",
    "\n",
    "### Primary Applications:\n",
    "\n",
    "1. **Skewed Distributions**\n",
    "   - Income and wealth data\n",
    "   - Property prices\n",
    "   - Insurance claims\n",
    "\n",
    "2. **Outlier-Prone Data**\n",
    "   - Experimental measurements\n",
    "   - Sensor data with errors\n",
    "   - Economic data with extreme values\n",
    "\n",
    "3. **Ordinal Data**\n",
    "   - Survey responses (Likert scales)\n",
    "   - Ranking data\n",
    "   - Educational grades\n",
    "\n",
    "4. **Survival Analysis**\n",
    "   - Medical research (median survival time)\n",
    "   - Reliability engineering\n",
    "   - Product lifetime analysis\n",
    "\n",
    "5. **Non-Normal Distributions**\n",
    "   - Asymmetric datasets\n",
    "   - Heavy-tailed distributions\n",
    "   - Bimodal distributions\n",
    "\n",
    "## 5. Limitations of Median\n",
    "\n",
    "### Statistical Limitations:\n",
    "\n",
    "1. **Ignores Magnitude of Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "722d7700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 median: 3.0\n",
      "Dataset 2 median: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Demonstration\n",
    "dataset1 = [1, 2, 3, 4, 5]\n",
    "dataset2 = [1, 2, 3, 4, 100]\n",
    "print(f\"Dataset 1 median: {np.median(dataset1)}\")\n",
    "print(f\"Dataset 2 median: {np.median(dataset2)}\")\n",
    "# Both have median 3, despite very different ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd8f63",
   "metadata": {},
   "source": [
    "##### 2. Less Statistically Efficient\n",
    "\n",
    "    - Requires larger sample sizes for precise estimation\n",
    "\n",
    "    - Higher sampling variability than mean for normal distributions\n",
    "\n",
    "##### 3. Limited Algebraic Utility\n",
    "\n",
    "    - Cannot be used in further mathematical operations\n",
    "\n",
    "    - Median of combined groups ≠ average of medians\n",
    "\n",
    "##### 4. Sensitivity to Sample Size\n",
    "\n",
    "    - Small samples may not represent population well\n",
    "\n",
    "    - Even number of observations requires averaging\n",
    "\n",
    "#### __Practical Limitations:__\n",
    "\n",
    "##### 1. Requires Sortable Data\n",
    "\n",
    "    - Not suitable for nominal categorical data\n",
    "\n",
    "    - Data must have meaningful order\n",
    "\n",
    "##### 2. Information Loss\n",
    "\n",
    "    - Discards information about extreme values\n",
    "\n",
    "    - Doesn't reflect the spread of data\n",
    "\n",
    "##### 3. Computational Complexity\n",
    "\n",
    "    - Requires sorting the entire dataset (O(n log n))\n",
    "\n",
    "    - Less efficient than mean for large datasets\n",
    "\n",
    "## 6. When to Use Median vs Mean\n",
    "\n",
    "| Scenario | Recommended Measure | Reason |\n",
    "|----------|---------------------|---------|\n",
    "| Symmetric, normal data | **Mean** | Uses all data, statistically efficient |\n",
    "| Skewed distributions | **Median** | Robust to asymmetry |\n",
    "| Outliers present | **Median** | Not influenced by extreme values |\n",
    "| Ordinal data | **Median** | Maintains order relationships |\n",
    "| Further calculations needed | **Mean** | Mathematical properties preserved |\n",
    "| Small sample sizes | **Both** | Compare for robustness |\n",
    "\n",
    "## 7. Advanced Topics\n",
    "\n",
    "### Weighted Median:\n",
    "For datasets where observations have different importance weights.\n",
    "\n",
    "### Median Absolute Deviation (MAD):\n",
    "A robust measure of variability based on the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1b56ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [12, 15, 18, 22, 25, 28, 32, 100]\n",
      "Median: 23.5\n",
      "MAD: 7.00\n",
      "Standard Deviation: 26.63\n",
      "MAD is more robust to outliers than standard deviation\n"
     ]
    }
   ],
   "source": [
    "# Example of MAD calculation\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "data = [12, 15, 18, 22, 25, 28, 32, 100]  # Contains outlier\n",
    "mad = median_abs_deviation(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Median: {np.median(data)}\")\n",
    "print(f\"MAD: {mad:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(\"MAD is more robust to outliers than standard deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09aae8",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "**Key Advantages:**\n",
    "- ✅ Robust to outliers and extreme values\n",
    "- ✅ Suitable for skewed distributions\n",
    "- ✅ Works with ordinal data\n",
    "- ✅ Easy to understand and interpret\n",
    "\n",
    "**Key Disadvantages:**\n",
    "- ❌ Ignores magnitude of all but middle values\n",
    "- ❌ Limited mathematical utility\n",
    "- ❌ Computationally intensive for large datasets\n",
    "- ❌ May "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432707cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Population vs Sample and Their Means\n",
    "\n",
    "## 1. Definitions\n",
    "\n",
    "### Population\n",
    "A **population** includes ALL members of a specified group that we want to study.\n",
    "- **Characteristics**: Complete set, parameters are fixed (but often unknown)\n",
    "- **Examples**: All students in a university, all trees in a forest, all registered voters in a country\n",
    "\n",
    "### Sample\n",
    "A **sample** is a subset of the population selected for study.\n",
    "- **Characteristics**: Representative subset, statistics are estimates of parameters\n",
    "- **Examples**: 200 students from a university, 50 trees from a forest, 1000 voters from a country\n",
    "\n",
    "## 2. Population Mean vs Sample Mean\n",
    "\n",
    "### Population Mean (μ)\n",
    "The average of ALL values in the entire population.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$ \\mu = \\frac{\\sum_{i=1}^{N} x_i}{N}\n",
    "$$\n",
    "Where:\n",
    "- $ N $ = Total number of elements in population\n",
    "- $ x_i $ = Each individual value in population\n",
    "- $ \\mu $ = Population mean (parameter)\n",
    "\n",
    "### Sample Mean (x̄)\n",
    "The average of values in a SAMPLE from the population.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$ \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n",
    "$$\n",
    "Where:\n",
    "- $ n $ = Total number of elements in sample\n",
    "- $ x_i $ = Each individual value in sample\n",
    "- $ \\bar{x} $ = Sample mean (statistic)\n",
    "\n",
    "## 3. Key Differences\n",
    "\n",
    "| Aspect | Population Mean (μ) | Sample Mean (x̄) |\n",
    "|--------|---------------------|------------------|\n",
    "| **Scope** | Entire population | Subset of population |\n",
    "| **Symbol** | μ (mu) | x̄ (x-bar) |\n",
    "| **Nature** | Parameter (fixed) | Statistic (varies by sample) |\n",
    "| **Calculation** | Uses all N elements | Uses n elements from sample |\n",
    "| **Purpose** | True value (often unknown) | Estimate of population mean |\n",
    "| **Variability** | No sampling variability | Subject to sampling error |\n",
    "\n",
    "## 4. Example Calculations\n",
    "Let's demonstrate with a comprehensive example using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e11b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== POPULATION vs SAMPLE MEAN DEMONSTRATION ===\n",
      "\n",
      "Example 1: Simulated Population - Student Test Scores\n",
      "Population size (N): 10,000\n",
      "Population mean (μ): 74.98\n",
      "Population standard deviation: 10.03\n",
      "\n",
      "Sampling from population:\n",
      "Sample size 30: mean = 75.73, error = +0.75\n",
      "Sample size 100: mean = 74.82, error = -0.16\n",
      "Sample size 500: mean = 75.50, error = +0.52\n",
      "\n",
      "Average of sample means: 75.35\n",
      "Population mean: 74.98\n",
      "\n",
      "Example 2: Real-world Scenario - City Housing Prices\n",
      "City housing population size: 10,000\n",
      "True average house price: $479.23K\n",
      "\n",
      "Real Estate Agent Samples:\n",
      "Mixed Areas     | Mean: $475.69K | Error: -3.54K (-0.7%)\n",
      "Affordable Areas | Mean: $294.38K | Error: -184.85K (-38.6%)\n",
      "Luxury Areas    | Mean: $1,244.31K | Error: +765.08K (+159.6%)\n",
      "\n",
      "Key Insight: Biased samples can lead to inaccurate estimates!\n",
      "\n",
      "Example 3: Sampling Distribution of the Mean\n",
      "Number of samples: 1,000\n",
      "Sample size: 50\n",
      "Mean of sampling distribution: 75.0101\n",
      "Population mean: 74.9786\n",
      "Standard deviation of sampling distribution: 1.3997\n",
      "Theoretical standard error (σ/√n): 1.4190\n",
      "Empirical vs Theoretical SE difference: 0.019378\n",
      "\n",
      "Example 4: 95% Confidence Interval\n",
      "Sample mean (x̄): 75.84\n",
      "Sample size: 200\n",
      "Margin of error: ±1.36\n",
      "95% Confidence Interval: (74.48, 77.21)\n",
      "Population mean (μ): 74.98\n",
      "Population mean within CI? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "print(\"=== POPULATION vs SAMPLE MEAN DEMONSTRATION ===\\n\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Example 1: Create a simulated population\n",
    "print(\"Example 1: Simulated Population - Student Test Scores\")\n",
    "population_size = 10000\n",
    "population_scores = np.random.normal(loc=75, scale=10, size=population_size)\n",
    "population_mean = np.mean(population_scores)\n",
    "\n",
    "print(f\"Population size (N): {population_size:,}\")\n",
    "print(f\"Population mean (μ): {population_mean:.2f}\")\n",
    "print(f\"Population standard deviation: {np.std(population_scores):.2f}\")\n",
    "\n",
    "# Take multiple samples from the population\n",
    "sample_sizes = [30, 100, 500]\n",
    "sample_means = []\n",
    "\n",
    "print(\"\\nSampling from population:\")\n",
    "for size in sample_sizes:\n",
    "    sample = np.random.choice(population_scores, size=size, replace=False)\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_means.append(sample_mean)\n",
    "    print(f\"Sample size {size}: mean = {sample_mean:.2f}, error = {sample_mean - population_mean:+.2f}\")\n",
    "\n",
    "print(f\"\\nAverage of sample means: {np.mean(sample_means):.2f}\")\n",
    "print(f\"Population mean: {population_mean:.2f}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Real-world scenario - House prices\n",
    "print(\"Example 2: Real-world Scenario - City Housing Prices\")\n",
    "\n",
    "# Simulate a city's housing prices (in thousands)\n",
    "city_houses = np.concatenate([\n",
    "    np.random.normal(300, 50, 6000),   # Affordable areas\n",
    "    np.random.normal(600, 100, 3000),  # Mid-range areas\n",
    "    np.random.normal(1200, 300, 1000)  # Luxury areas\n",
    "])\n",
    "\n",
    "population_housing_mean = np.mean(city_houses)\n",
    "\n",
    "print(f\"City housing population size: {len(city_houses):,}\")\n",
    "print(f\"True average house price: ${population_housing_mean:,.2f}K\")\n",
    "\n",
    "# Real estate agent takes samples from different areas\n",
    "print(\"\\nReal Estate Agent Samples:\")\n",
    "samples_data = []\n",
    "\n",
    "# Sample 1: Mixed areas\n",
    "sample_mixed = np.random.choice(city_houses, size=100, replace=False)\n",
    "samples_data.append(('Mixed Areas', sample_mixed))\n",
    "\n",
    "# Sample 2: Mostly affordable areas (biased sample)\n",
    "sample_affordable = np.random.choice(\n",
    "    city_houses[city_houses < 400], size=100, replace=False\n",
    ")\n",
    "samples_data.append(('Affordable Areas', sample_affordable))\n",
    "\n",
    "# Sample 3: Mostly luxury areas (biased sample)\n",
    "sample_luxury = np.random.choice(\n",
    "    city_houses[city_houses > 800], size=100, replace=False\n",
    ")\n",
    "samples_data.append(('Luxury Areas', sample_luxury))\n",
    "\n",
    "for sample_name, sample_data in samples_data:\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    error = sample_mean - population_housing_mean\n",
    "    error_percent = (error / population_housing_mean) * 100\n",
    "    print(f\"{sample_name:15} | Mean: ${sample_mean:,.2f}K | Error: {error:+.2f}K ({error_percent:+.1f}%)\")\n",
    "\n",
    "print(\"\\nKey Insight: Biased samples can lead to inaccurate estimates!\")\n",
    "print()\n",
    "\n",
    "# Example 3: Sampling distribution demonstration\n",
    "print(\"Example 3: Sampling Distribution of the Mean\")\n",
    "\n",
    "# Take 1000 samples of size 50 and calculate their means\n",
    "n_samples = 1000\n",
    "sample_size = 50\n",
    "sample_means_distribution = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    sample = np.random.choice(population_scores, size=sample_size, replace=False)\n",
    "    sample_means_distribution.append(np.mean(sample))\n",
    "\n",
    "sampling_dist_mean = np.mean(sample_means_distribution)\n",
    "sampling_dist_std = np.std(sample_means_distribution)\n",
    "population_std = np.std(population_scores)\n",
    "theoretical_se = population_std / np.sqrt(sample_size)\n",
    "\n",
    "print(f\"Number of samples: {n_samples:,}\")\n",
    "print(f\"Sample size: {sample_size}\")\n",
    "print(f\"Mean of sampling distribution: {sampling_dist_mean:.4f}\")\n",
    "print(f\"Population mean: {population_mean:.4f}\")\n",
    "print(f\"Standard deviation of sampling distribution: {sampling_dist_std:.4f}\")\n",
    "print(f\"Theoretical standard error (σ/√n): {theoretical_se:.4f}\")\n",
    "print(f\"Empirical vs Theoretical SE difference: {abs(sampling_dist_std - theoretical_se):.6f}\")\n",
    "\n",
    "# Example 4: Confidence interval demonstration\n",
    "print(\"\\nExample 4: 95% Confidence Interval\")\n",
    "\n",
    "sample_large = np.random.choice(population_scores, size=200, replace=False)\n",
    "sample_mean = np.mean(sample_large)\n",
    "sample_std = np.std(sample_large, ddof=1)  # ddof=1 for sample standard deviation\n",
    "n = len(sample_large)\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "z_critical = stats.norm.ppf(0.975)  # 1.96 for 95% CI\n",
    "margin_of_error = z_critical * (sample_std / np.sqrt(n))\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "print(f\"Sample mean (x̄): {sample_mean:.2f}\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Margin of error: ±{margin_of_error:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({confidence_interval[0]:.2f}, {confidence_interval[1]:.2f})\")\n",
    "print(f\"Population mean (μ): {population_mean:.2f}\")\n",
    "print(f\"Population mean within CI? {confidence_interval[0] <= population_mean <= confidence_interval[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c74415",
   "metadata": {},
   "source": [
    "## 5. Important Concepts\n",
    "\n",
    "### Sampling Error\n",
    "The difference between a sample statistic and the corresponding population parameter.\n",
    "\n",
    "$$ \\text{Sampling Error} = \\bar{x} - \\mu $$\n",
    "\n",
    "### Standard Error of the Mean\n",
    "Measures the variability of sample means around the population mean.\n",
    "$$ \\text{Standard Error} = \\frac{\\sigma}{\\sqrt{n}} $$\n",
    "Where:\n",
    "- $\\sigma$ = Population standard deviation\n",
    "- $n$ = Sample size\n",
    "\n",
    "### Central Limit Theorem\n",
    "For large sample sizes (n ≥ 30), the sampling distribution of the mean approaches a normal distribution, regardless of the population's distribution.\n",
    "\n",
    "### Law of Large Numbers\n",
    "As sample size increases, the sample mean converges to the population mean.\n",
    "\n",
    "## 6. Why We Use Samples\n",
    "\n",
    "### Practical Reasons:\n",
    "1. **Cost**: Studying entire populations is expensive\n",
    "2. **Time**: Population studies take too long\n",
    "3. **Feasibility**: Some populations are infinite or inaccessible\n",
    "4. **Destructive Testing**: Some measurements destroy the item\n",
    "\n",
    "### Statistical Principles:\n",
    "1. **Representativeness**: Proper sampling can accurately represent populations\n",
    "2. **Efficiency**: Well-designed samples provide precise estimates\n",
    "3. **Inference**: Allows statistical inference about populations\n",
    "\n",
    "## 7. Types of Sampling Methods\n",
    "\n",
    "### Probability Sampling:\n",
    "- **Simple Random Sampling**: Every member has equal chance\n",
    "- **Stratified Sampling**: Population divided into strata, then sampled\n",
    "- **Cluster Sampling**: Population divided into clusters, clusters randomly selected\n",
    "- **Systematic Sampling**: Every kth member selected\n",
    "\n",
    "### Non-Probability Sampling:\n",
    "- **Convenience Sampling**: Easily accessible members\n",
    "- **Purposive Sampling**: Researcher selects specific members\n",
    "- **Quota Sampling**: Predefined quotas for subgroups\n",
    "\n",
    "## 8. Best Practices\n",
    "\n",
    "### For Accurate Estimation:\n",
    "1. **Adequate Sample Size**: Larger samples reduce sampling error\n",
    "2. **Random Sampling**: Minimizes selection bias\n",
    "3. **Representative Sampling**: Ensure sample reflects population characteristics\n",
    "4. **Multiple Samples**: When possible, take multiple samples to assess variability\n",
    "\n",
    "### Common Pitfalls to Avoid:\n",
    "1. **Selection Bias**: Non-random selection methods\n",
    "2. **Small Sample Sizes**: High variability and unreliable estimates\n",
    "3. **Non-response Bias**: Missing data from certain groups\n",
    "4. **Sampling Frame Errors**: Incomplete or inaccurate population lists\n",
    "\n",
    "## 9. Applications in Real Research\n",
    "\n",
    "### Scientific Research:\n",
    "- Clinical trials (sample of patients)\n",
    "- Environmental studies (sample of locations)\n",
    "- Social surveys (sample of population)\n",
    "\n",
    "### Business Applications:\n",
    "- Market research (sample of customers)\n",
    "- Quality control (sample of products)\n",
    "- Employee surveys (sample of staff)\n",
    "\n",
    "### Government and Policy:\n",
    "- Census sampling (between full censuses)\n",
    "- Economic indicators (sample of businesses)\n",
    "- Public health studies (sample of population)\n",
    "\n",
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Population Mean (μ)**: True average, often unknown\n",
    "- **Sample Mean (x̄)**: Estimate based on sample data\n",
    "- **Sampling Error**: Natural variation between samples\n",
    "- **Standard Error**: Measures precision of sample mean\n",
    "\n",
    "### Statistical Wisdom:\n",
    "- \"The sample mean is an unbiased estimator of the population mean\"\n",
    "- \"Larger samples provide more precise estimates\"\n",
    "- \"Random sampling is crucial for valid inference\"\n",
    "- \"Always consider potential biases in sampling\"\n",
    "\n",
    "### Final Note:\n",
    "Understanding the relationship between population and sample means is fundamental to statistical inference and forms the basis for most statistical analyses in research and practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046eefff",
   "metadata": {},
   "source": [
    "---\n",
    "# __Variability and Dispersion/Spread:__\n",
    "Variability, often referred to as dispersion/spread, is the heartbeat of a dataset. It measures how much individual data points differ from each other and from the central tendency (like the mean or median). Imagine a world where everyone thinks, acts, and looks the same-pretty boring, right? Well, variability is the statistical counterpart that celebrates the differences in our data world. It helps us understand the diversity and distribution of values within a dataset.\n",
    "\n",
    "- **Diversity means:** The extent to which data points differ from each other. High variability means data points are spread out widely, while low variability indicates they are clustered closely together.\n",
    "\n",
    "- Data spread is the __Heartbeat of data__\n",
    "- We have to think beyond the Average\n",
    "- Decision Making: Understanding variability helps in making informed decisions based on data insights.\n",
    "\n",
    "Types of Variability Measures:\n",
    "1. Range of spread: The difference between the maximum and minimum values in a dataset.\n",
    "2. IQR: The range within which the central 50% of the data lies, calculated as the difference between the 75th percentile (Q3) and the 25th percentile (Q1).\n",
    "3. Variance: The average of the squared differences from the mean, providing a measure of how data points spread out around the mean.\n",
    "4. Standard Deviation: The square root of the variance, representing the average distance of data points from the mean.\n",
    "5. Standard Error: The standard deviation of the sampling distribution of a statistic, often the mean, indicating how much the sample mean is expected to vary from the true population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "126dd32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='fare', ylabel='Count'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df, x= 'fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d91c4fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba8a4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Read the Blog: [Click here](https://codanics.com/variability-in-statistics/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
